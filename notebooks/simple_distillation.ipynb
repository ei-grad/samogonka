{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergevkim/anaconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        subset: Subset,\n",
    "        transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergevkim/anaconda3/envs/py310/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:95: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/Users/sergevkim/anaconda3/envs/py310/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:114: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/Users/sergevkim/anaconda3/envs/py310/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:133: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = './data/',\n",
    "        batch_size: int = 8,\n",
    "        num_workers: int = 4,\n",
    "        shuffle: bool = False,\n",
    "        train_transforms: Optional[Callable] = None,\n",
    "        val_transforms: Optional[Callable] = None,\n",
    "        test_transforms: Optional[Callable] = None,\n",
    "        val_size: float = 0.25,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.shuffle = shuffle\n",
    "        self.train_transforms = train_transforms\n",
    "        self.val_transforms = val_transforms\n",
    "        self.test_transforms = test_transforms\n",
    "        self.val_size = val_size\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        Path(self.data_dir).mkdir(parents=True, exist_ok=True)\n",
    "        CIFAR10(root=self.data_dir, train=True, download=True)\n",
    "        CIFAR10(root=self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage == 'fit' or stage is None:\n",
    "            trainval_dataset = CIFAR10(\n",
    "                root=self.data_dir,\n",
    "                train=True,\n",
    "            )\n",
    "            train_indices, val_indices = train_test_split(\n",
    "                np.arange(len(trainval_dataset)),\n",
    "                test_size=self.val_size,\n",
    "                stratify=True,\n",
    "            )\n",
    "            train_subset = Subset(trainval_dataset, train_indices)\n",
    "            val_subset = Subset(trainval_dataset, val_indices)\n",
    "\n",
    "            train_transforms = self.default_transforms() \\\n",
    "                if self.train_transforms is None else self.train_transforms\n",
    "            val_transforms = self.default_transforms() \\\n",
    "                if self.val_transforms is None else self.val_transforms\n",
    "            self.train_dataset = \\\n",
    "                CIFAR10Dataset(train_subset, transform=train_transforms)\n",
    "            self.val_dataset = \\\n",
    "                CIFAR10Dataset(val_subset, transform=val_transforms)\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            test_transforms = self.default_transforms() \\\n",
    "                if self.test_transforms is None else self.test_transforms\n",
    "            self.test_dataset = CIFAR10(\n",
    "                root=self.data_dir,\n",
    "                train=False,\n",
    "                transform=test_transforms,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=self.shuffle,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def default_transforms(self) -> Callable:\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "dm = CIFAR10DataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from einops.layers.torch import Rearrange\n",
    "from torchvision.models import resnet18, resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Model(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.feature_extractor = nn.Sequential(*(list(model.children())[:-2]))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            Rearrange('bs c 1 1 -> bs c'),\n",
    "            nn.Linear(in_features=2048, out_features=10, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, input_mode: str = 'images'):\n",
    "        features = None\n",
    "        if input_mode == 'images':\n",
    "            features = self.extract_features(x)\n",
    "        elif input_mode == 'features':\n",
    "            features = x\n",
    "\n",
    "        outputs = self.head(features)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Model(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        model = resnet18(weights=None)\n",
    "        self.feature_extractor = nn.Sequential(*(list(model.children())[:-2]))\n",
    "        self.neck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=2048, kernel_size=1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            Rearrange('bs c 1 1 -> bs c'),\n",
    "            nn.Linear(in_features=2048, out_features=10, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, input_mode: str = 'images'):\n",
    "        features = None\n",
    "        if input_mode == 'images':\n",
    "            features = self.extract_features(x)\n",
    "        elif input_mode == 'features':\n",
    "            features = x\n",
    "\n",
    "        outputs = self.head(features)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.neck(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "student = ResNet18Model()\n",
    "teacher = ResNet50Model()\n",
    "x = torch.randn(8, 3, 224, 224)\n",
    "assert student.extract_features(x).shape == teacher.extract_features(x).shape\n",
    "assert teacher(x).shape == student(x).shape\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba4ef7194939a0f598f7307e514728c3da9e8572e38d9dd10d8b6f91a1a50201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
